{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取当前日期\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "outdir = 'outdir'\n",
    "\n",
    "\n",
    "# 构建导出的pth文件名以及ONNX文件名\n",
    "pth_file_path = os.path.join(outdir, f'eeg_anxiety-best_model_{current_date}.pth')\n",
    "onnx_file_path = os.path.join(outdir, f\"eeg_anxiety-best_model_{current_date}.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 0.4873095154762268 Test Accuracy: 0.5526373385861238\n",
      "Best Accuracy Model: 0.5526373385861238\n",
      "Epoch: 1 Train Loss: 0.5010685920715332 Test Accuracy: 0.5762748960385204\n",
      "Best Accuracy Model: 0.5762748960385204\n",
      "Epoch: 2 Train Loss: 0.5225220918655396 Test Accuracy: 0.5821842854016196\n",
      "Best Accuracy Model: 0.5821842854016196\n",
      "Epoch: 3 Train Loss: 0.5948150157928467 Test Accuracy: 0.585905012037645\n",
      "Best Accuracy Model: 0.585905012037645\n",
      "Epoch: 4 Train Loss: 0.5317538380622864 Test Accuracy: 0.5845918144014007\n",
      "Epoch: 5 Train Loss: 0.5757097005844116 Test Accuracy: 0.6111840665353468\n",
      "Best Accuracy Model: 0.6111840665353468\n",
      "Epoch: 6 Train Loss: 0.48437821865081787 Test Accuracy: 0.6201575837163493\n",
      "Best Accuracy Model: 0.6201575837163493\n",
      "Epoch: 7 Train Loss: 0.5017504096031189 Test Accuracy: 0.6452177719413439\n",
      "Best Accuracy Model: 0.6452177719413439\n",
      "Epoch: 8 Train Loss: 0.5092822313308716 Test Accuracy: 0.6226745458524842\n",
      "Epoch: 9 Train Loss: 0.5326528549194336 Test Accuracy: 0.6418253447143795\n",
      "Epoch: 10 Train Loss: 0.49828118085861206 Test Accuracy: 0.6399649813963668\n",
      "Epoch: 11 Train Loss: 0.49339333176612854 Test Accuracy: 0.6503611293499671\n",
      "Best Accuracy Model: 0.6503611293499671\n",
      "Epoch: 12 Train Loss: 0.514358639717102 Test Accuracy: 0.6522214926679799\n",
      "Best Accuracy Model: 0.6522214926679799\n",
      "Epoch: 13 Train Loss: 0.5137084722518921 Test Accuracy: 0.6422630772597943\n",
      "Epoch: 14 Train Loss: 0.5465680360794067 Test Accuracy: 0.6492667979864303\n",
      "Epoch: 15 Train Loss: 0.4815128445625305 Test Accuracy: 0.6562705187130663\n",
      "Best Accuracy Model: 0.6562705187130663\n",
      "Epoch: 16 Train Loss: 0.4608510136604309 Test Accuracy: 0.6644780039395929\n",
      "Best Accuracy Model: 0.6644780039395929\n",
      "Epoch: 17 Train Loss: 0.4985038638114929 Test Accuracy: 0.6408404464871963\n",
      "Epoch: 18 Train Loss: 0.5378568172454834 Test Accuracy: 0.6504705624863208\n",
      "Epoch: 19 Train Loss: 0.44211676716804504 Test Accuracy: 0.6596629459400306\n",
      "Epoch: 20 Train Loss: 0.5044564604759216 Test Accuracy: 0.6544101553950536\n",
      "Epoch: 21 Train Loss: 0.558565080165863 Test Accuracy: 0.6599912453490917\n",
      "Epoch: 22 Train Loss: 0.3781801462173462 Test Accuracy: 0.668308163711972\n",
      "Best Accuracy Model: 0.668308163711972\n",
      "Epoch: 23 Train Loss: 0.48929211497306824 Test Accuracy: 0.6525497920770409\n",
      "Epoch: 24 Train Loss: 0.47419309616088867 Test Accuracy: 0.6523309258043336\n",
      "Epoch: 25 Train Loss: 0.4057159423828125 Test Accuracy: 0.6555044867585905\n",
      "Epoch: 26 Train Loss: 0.5125001668930054 Test Accuracy: 0.6522214926679799\n",
      "Epoch: 27 Train Loss: 0.40788066387176514 Test Accuracy: 0.6434668417596848\n",
      "Epoch: 28 Train Loss: 0.7208882570266724 Test Accuracy: 0.6534252571678705\n",
      "Epoch: 29 Train Loss: 0.49065178632736206 Test Accuracy: 0.6538629897132852\n",
      "Confusion Matrix:\n",
      "[[3213 1356]\n",
      " [1807 2762]]\n",
      "Best Accuracy 0.668308163711972\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, positive_file, negative_file):\n",
    "        # Load positive samples\n",
    "        with open(positive_file, 'rb') as f:\n",
    "            self.positive_samples = pickle.load(f)\n",
    "        \n",
    "        # Load negative samples\n",
    "        with open(negative_file, 'rb') as f:\n",
    "            self.negative_samples = pickle.load(f)\n",
    "\n",
    "        # Ensure both sets have the same length\n",
    "        self.length = min(len(self.positive_samples), len(self.negative_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Concatenate positive and negative samples to form a batch\n",
    "        subject, positive_feature, positive_label = self.positive_samples[idx % len(self.positive_samples)]\n",
    "        subject, negative_feature, negative_label = self.negative_samples[idx % len(self.negative_samples)]\n",
    "        return torch.tensor(positive_feature), torch.tensor(negative_feature)\n",
    "\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)  # Input size 100, output size 64\n",
    "        self.dropout1 = nn.Dropout(p=0.3)  # Dropout with a probability of 0.5\n",
    "        self.fc2 = nn.Linear(64, 32)   # Input size 64, output size 32\n",
    "        self.dropout2 = nn.Dropout(p=0.3)  # Dropout with a probability of 0.5\n",
    "        self.fc3 = nn.Linear(32, 1)    # Input size 32, output size 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Define paths to your data files\n",
    "train_positive_file = './samples/train_positive_samples.pkl'\n",
    "train_negative_file = './samples/train_negative_samples.pkl'\n",
    "test_positive_file = './samples/test_positive_samples.pkl'\n",
    "test_negative_file = './samples/test_negative_samples.pkl'\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_positive_file, train_negative_file)\n",
    "test_dataset = CustomDataset(test_positive_file, test_negative_file)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleDNN()\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)  # Adam optimizer\n",
    "\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(30):  # Train for 10 epochs\n",
    "    for batch_idx, (positive_batch, negative_batch) in enumerate(train_loader):\n",
    "        # Concatenate positive and negative batches\n",
    "        inputs = torch.cat((positive_batch, negative_batch), dim=0)\n",
    "        labels = torch.cat((torch.ones(positive_batch.size(0), 1), torch.zeros(negative_batch.size(0), 1)), dim=0)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs.float())  # Forward pass\n",
    "        loss = criterion(outputs, labels.float())  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "    # Testing loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_correct = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for positive_batch, negative_batch in test_loader:\n",
    "            inputs = torch.cat((positive_batch, negative_batch), dim=0)\n",
    "            labels = torch.cat((torch.ones(positive_batch.size(0), 1), torch.zeros(negative_batch.size(0), 1)), dim=0)\n",
    "            \n",
    "            outputs = model(inputs.float())\n",
    "            predicted = (outputs > 0.5).float()  # Threshold at 0.5\n",
    "            total_samples += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_predictions.extend(predicted.numpy())\n",
    "\n",
    "    accuracy = test_correct / total_samples\n",
    "    print(f'Epoch: {epoch} Train Loss: {loss} Test Accuracy: {accuracy}')\n",
    "\n",
    "    # Save the best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), pth_file_path)\n",
    "        print(\"Best Accuracy Model: {}\".format(best_accuracy))\n",
    "\n",
    "        # Export the best model to ONNX\n",
    "        dummy_input = torch.randn(1, 128)\n",
    "        torch.onnx.export(model, dummy_input, onnx_file_path, input_names=['input'], output_names=['output'])\n",
    "    \n",
    "\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(pth_file_path))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Best Accuracy\", best_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import glob\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test for Negative subjects:\n",
      "Subject: A20, Accuracy: 0.59\n",
      "Subject: A23, Accuracy: 0.89\n",
      "Subject: A16, Accuracy: 0.68\n",
      "Subject: A03, Accuracy: 0.72\n",
      "Subject: A22, Accuracy: 0.87\n",
      "Subject: A17, Accuracy: 0.74\n",
      "Subject: A18, Accuracy: 0.83\n",
      "Subject: A12, Accuracy: 0.73\n",
      "\n",
      "Test for Positive subjects:\n",
      "Subject: 20240619_2A05, Accuracy: 0.27\n",
      "Subject: 20240619_2A06, Accuracy: 0.70\n",
      "Subject: 20240626_2A51, Accuracy: 0.94\n",
      "Subject: 20240710_2A02, Accuracy: 0.38\n",
      "Subject: 20240710_2A13, Accuracy: 0.76\n",
      "Subject: 20240710_2A38, Accuracy: 0.82\n",
      "Subject: 20240717_2A08, Accuracy: 0.61\n",
      "Subject: 20240717_2A37, Accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "def get_onnxfile():\n",
    "    outdir = './outdir'\n",
    "    onnx_files = glob.glob(os.path.join(outdir, '*.onnx'))\n",
    "    # 如果找到的文件不为空\n",
    "    if onnx_files:\n",
    "        # 按文件名排序\n",
    "        onnx_files.sort()\n",
    "\n",
    "        # 选择最后一个文件\n",
    "        last_onnx_file = onnx_files[-1]\n",
    "        return last_onnx_file\n",
    "\n",
    "onnx_model_path = get_onnxfile()\n",
    "def get_onnxfile():\n",
    "    outdir = './outdir'\n",
    "    onnx_files = glob.glob(os.path.join(outdir, '*.onnx'))\n",
    "    # 如果找到的文件不为空\n",
    "    if onnx_files:\n",
    "        # 按文件名排序\n",
    "        onnx_files.sort()\n",
    "\n",
    "        # 选择最后一个文件\n",
    "        last_onnx_file = onnx_files[-1]\n",
    "        return last_onnx_file\n",
    "\n",
    "onnx_model_path = get_onnxfile()\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# 预测函数\n",
    "def predict(features):\n",
    "    inputs = {ort_session.get_inputs()[0].name: features}\n",
    "    outputs = ort_session.run(None, inputs)\n",
    "    return outputs[0]\n",
    "\n",
    "\n",
    "for filePath in [test_negative_file, test_positive_file]:\n",
    "    if filePath == test_negative_file:\n",
    "        print(\"\\nTest for Negative subjects:\")\n",
    "    else:\n",
    "        print(\"\\nTest for Positive subjects:\")\n",
    "\n",
    "    # 加载测试数据集\n",
    "    with open(filePath, 'rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "\n",
    "    # 计算每个 subject 的准确率\n",
    "    subject_results = defaultdict(list)\n",
    "\n",
    "    for subject, features, label in test_data:\n",
    "        features = np.array(features, dtype=np.float32)  # 确保 features 的数据类型与模型输入匹配\n",
    "        features = features.reshape(1, -1)  # 调整形状以匹配模型输入\n",
    "        prediction = predict(features)\n",
    "        predicted_label = (prediction >= 0.5).astype(int)  # 使用阈值 0.5 将预测概率转换为类标签\n",
    "        subject_results[subject].append((predicted_label, label))\n",
    "\n",
    "    subject_accuracies = {}\n",
    "    for subject, results in subject_results.items():\n",
    "        correct = sum(1 for pred, label in results if pred == label)\n",
    "        accuracy = correct / len(results)\n",
    "        subject_accuracies[subject] = accuracy\n",
    "\n",
    "    # 输出每个 subject 的准确度\n",
    "    for subject, accuracy in subject_accuracies.items():\n",
    "        print(f'Subject: {subject}, Accuracy: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
